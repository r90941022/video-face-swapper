# Video Changer

æ™ºèƒ½å½±ç‰‡æ›è‡‰ç³»çµ± - è‡ªå‹•è¾¨è­˜ä¸»è¦äººç‰©ä¸¦é€²è¡Œé«˜å“è³ªè‡‰éƒ¨æ›¿æ›

Intelligent video face swapping system with automatic dominant face detection and GPU acceleration.

## ğŸ“‹ ç›®éŒ„ / Table of Contents

- [å¿«é€Ÿé–‹å§‹ Quick Start](#å¿«é€Ÿé–‹å§‹-quick-start)
- [åŠŸèƒ½ç‰¹è‰² Features](#åŠŸèƒ½ç‰¹è‰²-features)
- [ç³»çµ±éœ€æ±‚ Requirements](#ç³»çµ±éœ€æ±‚-system-requirements)
- [å®‰è£æŒ‡å— Installation](#å®‰è£æŒ‡å—-installation)
- [ä½¿ç”¨èªªæ˜ Usage](#ä½¿ç”¨èªªæ˜-usage)
- [é…ç½®èªªæ˜ Configuration](#é…ç½®èªªæ˜-configuration)
- [æ•ˆèƒ½è¡¨ç¾ Performance](#æ•ˆèƒ½è¡¨ç¾-performance)
- [æŠ€è¡“æ¶æ§‹ Architecture](#æŠ€è¡“æ¶æ§‹-technical-architecture)
- [å¸¸è¦‹å•é¡Œ FAQ](#å¸¸è¦‹å•é¡Œ-faq)
- [æ•…éšœæ’é™¤ Troubleshooting](#æ•…éšœæ’é™¤-troubleshooting)

---

## ğŸš€ å¿«é€Ÿé–‹å§‹ Quick Start

### ğŸ¯ æœ€ç°¡å–®çš„æ–¹å¼ - ä¸€éµåŸ·è¡Œ / Easiest Way - One Command

```bash
# 1. å°‡å½±ç‰‡æ”¾å…¥ input/ ç›®éŒ„
cp your_video.mp4 input/

# 2. åŸ·è¡Œ run.sh (è‡ªå‹•è™•ç†æ‰€æœ‰å½±ç‰‡å’Œäººè‡‰)
./run.sh
```

**å®Œæˆï¼** è¼¸å‡ºå½±ç‰‡åœ¨ `output/final/` ç›®éŒ„

**ç‰¹é»:**
- âœ… è‡ªå‹•æƒæ input/ è£¡çš„æ‰€æœ‰å½±ç‰‡
- âœ… è‡ªå‹•å¥—ç”¨ target_images/ è£¡çš„æ‰€æœ‰äººè‡‰
- âœ… è‡ªå‹•ç”¢ç”Ÿæ‰€æœ‰çµ„åˆçš„æ›è‡‰å½±ç‰‡
- âœ… ä¸éœ€è¦è¼¸å…¥ä»»ä½•åƒæ•¸æˆ–æª”æ¡ˆåç¨±

---

### ğŸ“‹ é€²éšæ–¹å¼ - æ‰‹å‹•æŒ‡å®š / Advanced - Manual Specification

å¦‚æœéœ€è¦ç²¾ç¢ºæ§åˆ¶è™•ç†å“ªå€‹å½±ç‰‡å’Œäººè‡‰:

```bash
# æ¿€æ´»ç’°å¢ƒ
source venv/bin/activate

# åŸ·è¡Œç‰¹å®šçµ„åˆ
python main.py --source input/video.mp4 \
               --target target_images/person1 \
               --output output/final/result.mp4 \
               --auto
```

---

## âœ¨ åŠŸèƒ½ç‰¹è‰² Features

âœ… **æ™ºèƒ½å–æ¨£ Smart Sampling**
- ä¸åªæƒæå‰ 100 å¹€ï¼Œè€Œæ˜¯å‡å‹»å–æ¨£æ•´éƒ¨å½±ç‰‡
- æ™ºèƒ½èª¿æ•´å–æ¨£ç­–ç•¥ï¼šçŸ­å½±ç‰‡å¯†é›†å–æ¨£ï¼Œé•·å½±ç‰‡é–“éš”å–æ¨£

âœ… **è‡ªå‹•åµæ¸¬ä¸»è§’ Dominant Face Detection**
- è‡ªå‹•è¾¨è­˜å½±ç‰‡ä¸­çš„ä¸»è¦äººç‰©
- åŸºæ–¼å‡ºç¾é »ç‡ã€è‡‰éƒ¨å¤§å°ã€æ¸…æ™°åº¦çš„ç¶œåˆè©•åˆ†

âœ… **é«˜å“è³ªæ›è‡‰ High-Quality Swapping**
- ä½¿ç”¨ InsightFace inswapper_128 æ¨¡å‹
- è‡ªç„¶ç„¡é•å’Œçš„æ›è‡‰æ•ˆæœ

âœ… **Face Tracking æŠ€è¡“**
- å³ä½¿éƒ¨åˆ† frame åµæ¸¬å¤±æ•—ä¹Ÿèƒ½ç¶­æŒé€£çºŒæ€§
- è‡ªå‹•è¿½è¹¤å‰ä¸€ frame çš„è‡‰éƒ¨ä½ç½®

âœ… **GPU åŠ é€Ÿ GPU Acceleration**
- è‡ªå‹•åµæ¸¬ä¸¦ä½¿ç”¨ NVIDIA GPU
- è™•ç†é€Ÿåº¦æå‡ 10-20 å€

âœ… **å®Œæ•´ä¿ç•™åŸå½±ç‰‡å“è³ª**
- ç¶­æŒåŸ FPSã€è§£æåº¦
- å®Œæ•´ä¿ç•™éŸ³è»Œ

---

## ğŸ’» ç³»çµ±éœ€æ±‚ System Requirements

### ç¡¬é«”éœ€æ±‚ Hardware

| é …ç›® | æœ€ä½ | å»ºè­° |
|------|------|------|
| **CPU** | Intel i5 / AMD Ryzen 5 | Intel i7 / AMD Ryzen 7 |
| **RAM** | 8GB | 16GB+ |
| **GPU** | ç„¡ (å¯ç”¨ CPU) | NVIDIA GPU 8GB+ VRAM |
| **å„²å­˜** | 10GB å¯ç”¨ç©ºé–“ | 20GB+ SSD |

### è»Ÿé«”éœ€æ±‚ Software

- **ä½œæ¥­ç³»çµ±**: Linux (Ubuntu 20.04+) / Windows 10+ / macOS
- **Python**: 3.8 - 3.11
- **CUDA**: 12.x (GPU ä½¿ç”¨è€…)
- **Driver**: NVIDIA Driver 535+ (GPU ä½¿ç”¨è€…)
- **FFmpeg**: 4.0+

---

## ğŸ“¦ å®‰è£æŒ‡å— Installation

### 1. ç³»çµ±æº–å‚™

#### Ubuntu/Linux
```bash
# æ›´æ–°ç³»çµ±
sudo apt-get update
sudo apt-get upgrade

# å®‰è£ FFmpeg
sudo apt-get install ffmpeg

# å®‰è£ Python 3.8+
sudo apt-get install python3 python3-pip python3-venv
```

#### æª¢æŸ¥ GPU (å¯é¸ä½†å»ºè­°)
```bash
# æª¢æŸ¥ NVIDIA GPU
nvidia-smi

# æª¢æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version
```

### 2. å»ºç«‹å°ˆæ¡ˆç’°å¢ƒ

```bash
# é€²å…¥å°ˆæ¡ˆç›®éŒ„
cd /home/user/hjchen/video-changer

# å»ºç«‹è™›æ“¬ç’°å¢ƒ
python3 -m venv venv

# æ¿€æ´»è™›æ“¬ç’°å¢ƒ
source venv/bin/activate
```

### 3. å®‰è£ Python ä¾è³´å¥—ä»¶

```bash
# å®‰è£åŸºæœ¬å¥—ä»¶
pip install -r requirements.txt
```

### 4. å®‰è£ GPU æ”¯æ´ (å¼·çƒˆå»ºè­°)

**å°æ–¼ CUDA 12.x ç³»çµ±ï¼š**
```bash
pip uninstall -y onnxruntime-gpu onnxruntime
pip install onnxruntime-gpu==1.19.2 \
    --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/
```

**é©—è­‰ GPU å®‰è£ï¼š**
```bash
python -c "import onnxruntime as ort; print('GPU available:', 'CUDAExecutionProvider' in ort.get_available_providers())"
```

### 5. æº–å‚™ç›®éŒ„çµæ§‹

```bash
# ç¢ºèªç›®éŒ„çµæ§‹
ls -la
# æ‡‰è©²çœ‹åˆ°ï¼š
# input/           - æ”¾ç½®è¼¸å…¥å½±ç‰‡
# target_images/   - æ”¾ç½®ç›®æ¨™è‡‰éƒ¨åœ–ç‰‡
# output/          - è¼¸å‡ºçµæœ
# src/             - åŸå§‹ç¢¼
# main.py          - ä¸»ç¨‹å¼
# config.yaml      - é…ç½®æª”
```

### 6. æ¸¬è©¦å®‰è£

```bash
# åŸ·è¡Œæ¸¬è©¦
python main.py --help

# æ‡‰è©²çœ‹åˆ°ç¨‹å¼åƒæ•¸èªªæ˜
```

---

## ğŸ“‚ å°ˆæ¡ˆçµæ§‹ Project Structure

```
video-changer/
â”œâ”€â”€ main.py                      # ä¸»ç¨‹å¼å…¥å£
â”œâ”€â”€ config.yaml                  # é…ç½®æª”æ¡ˆ
â”œâ”€â”€ requirements.txt             # Python ä¾è³´å¥—ä»¶
â”œâ”€â”€ README.md                    # æœ¬æ–‡ä»¶
â”‚
â”œâ”€â”€ src/                         # åŸå§‹ç¢¼ç›®éŒ„
â”‚   â”œâ”€â”€ frame_sampler.py        # æ™ºèƒ½ frame å–æ¨£æ¨¡çµ„
â”‚   â”œâ”€â”€ face_detector.py        # è‡‰éƒ¨åµæ¸¬æ¨¡çµ„ (InsightFace)
â”‚   â”œâ”€â”€ dominant_analyzer.py    # ä¸»è§’è¾¨è­˜æ¨¡çµ„
â”‚   â”œâ”€â”€ face_swapper.py         # è‡‰éƒ¨äº¤æ›æ ¸å¿ƒæ¨¡çµ„
â”‚   â”œâ”€â”€ video_processor.py      # å½±ç‰‡è™•ç†ç®¡é“
â”‚   â””â”€â”€ gpu_utils.py            # GPU å·¥å…·æ¨¡çµ„
â”‚
â”œâ”€â”€ input/                       # è¼¸å…¥å½±ç‰‡ç›®éŒ„
â”‚   â”œâ”€â”€ video1.mp4
â”‚   â””â”€â”€ video2.mp4
â”‚
â”œâ”€â”€ target_images/              # ç›®æ¨™è‡‰éƒ¨åœ–ç‰‡ç›®éŒ„
â”‚   â”œâ”€â”€ person1/                # ç¬¬ä¸€çµ„è‡‰éƒ¨åœ–ç‰‡
â”‚   â”‚   â”œâ”€â”€ photo1.jpg
â”‚   â”‚   â”œâ”€â”€ photo2.jpg
â”‚   â”‚   â””â”€â”€ photo3.jpg
â”‚   â””â”€â”€ person2/                # ç¬¬äºŒçµ„è‡‰éƒ¨åœ–ç‰‡
â”‚       â”œâ”€â”€ photo1.jpg
â”‚       â””â”€â”€ photo2.jpg
â”‚
â”œâ”€â”€ output/                     # è¼¸å‡ºç›®éŒ„
â”‚   â”œâ”€â”€ final/                  # æœ€çµ‚è¼¸å‡ºå½±ç‰‡
â”‚   â”‚   â””â”€â”€ result.mp4
â”‚   â””â”€â”€ analysis/               # åˆ†æçµæœ (å¯é¸)
â”‚       â”œâ”€â”€ preview_comparison.jpg
â”‚       â””â”€â”€ dominant_face_crops/
â”‚
â””â”€â”€ venv/                       # Python è™›æ“¬ç’°å¢ƒ
```

## Usage

### Basic Usage

1. **Prepare your inputs:**
   - Place source video in `input/` directory
   - Place 3-5 target face photos in `target_images/` directory
     - Use different angles (front, left, right) for best results
     - Photos should be clear and well-lit
     - Face should be clearly visible

2. **Run in step-by-step mode (recommended for first time):**
```bash
python main.py \
  --source input/source_video.mp4 \
  --target target_images/ \
  --output output/final/result.mp4
```

3. **Or run in automatic mode:**
```bash
python main.py \
  --source input/source_video.mp4 \
  --target target_images/ \
  --output output/final/result.mp4 \
  --auto
```

### Step-by-Step Mode

The default mode shows you the results at each stage and waits for confirmation:

1. **Frame Sampling**: View sampled frames grid
2. **Face Detection**: View detected faces with bounding boxes
3. **Dominant Face Analysis**: View identified dominant face crops and statistics
4. **Target Face Preparation**: Confirm target faces extracted correctly
5. **Preview**: View side-by-side comparison of 10 sample frames
6. **Full Processing**: Process entire video

At each step, you can:
- Press `y` to continue
- Press `n` to stop and adjust settings
- Press `q` to quit

### Configuration

Edit `config.yaml` to customize:

**Frame Sampling:**
```yaml
frame_sampling:
  target_samples: 200              # Number of frames to analyze
  min_interval_seconds: 1.5        # Sampling interval for long videos
```

**Dominant Face Detection:**
```yaml
dominant_face:
  weight_frequency: 0.4            # Weight for appearance frequency
  weight_size: 0.4                 # Weight for face size
  weight_clarity: 0.2              # Weight for face quality
```

**Face Processing:**
```yaml
face_processing:
  face_enhancer: gfpgan_1.4        # Use GFPGAN enhancement
  blend_ratio: 0.75                # Blending strength
```

**Video Output:**
```yaml
video:
  keep_fps: true                   # Preserve original FPS
  keep_audio: true                 # Preserve audio
  output_quality: high             # low, medium, or high
```

**Hardware:**
```yaml
hardware:
  execution_provider: cuda         # cuda, cpu, or coreml (Mac)
```

## How It Works

### 1. Smart Frame Sampling
Instead of analyzing only the first 100 frames, the system:
- Calculates video duration
- Samples frames uniformly across the entire video
- For short videos (<60s): samples densely
- For long videos (â‰¥60s): samples every 1-2 seconds
- Ensures at least 200 frames for robust analysis

### 2. Dominant Face Detection
The system identifies the main person by:
- Detecting all faces in sampled frames
- Tracking unique identities using face embeddings (cosine similarity)
- Scoring each identity based on:
  - **Frequency** (40%): How often they appear
  - **Size** (40%): Average face size in frames
  - **Clarity** (20%): Detection confidence
- Selecting the highest-scoring identity as dominant

### 3. Face Swapping
For each frame in the video:
- Detect all faces
- Match faces to dominant identity using embeddings
- Swap matched faces with target face using InsightFace inswapper
- Optional: Enhance face quality with GFPGAN
- Blend seamlessly with original frame

### 4. Video Reconstruction
- Maintains original resolution, FPS, and quality
- Preserves audio track
- Uses H.264 encoding with configurable quality

## Target Face Guidelines

For best results, provide 3-5 photos of the target face with:
- **Variety of angles**: front, left profile, right profile
- **Good lighting**: well-lit, no harsh shadows
- **Clear face**: face should be clearly visible
- **High resolution**: at least 512x512 pixels
- **Neutral expression**: works best, but not required

## Output Files

After processing, you'll find:

**Analysis Results** (`output/analysis/`):
- `sampled_frames_grid.jpg` - Grid of sampled frames
- `face_tracking_visualization.jpg` - Tracked faces across frames
- `dominant_face_report.txt` - Detailed statistics
- `dominant_face_crops/` - Crops of dominant face from various frames
- `preview_comparison.jpg` - Before/after comparison

**Processed Videos** (`output/final/`):
- Your final video with replaced faces

**Debug Files** (`output/detected_faces/`, `output/sampled_frames/`):
- Individual frames with annotations (if debug enabled)

## Performance

Processing speed depends on:
- Video resolution and length
- Hardware (GPU vs CPU)
- Face enhancement enabled/disabled

**Typical speeds (with GPU):**
- 720p video: ~10-15 fps
- 1080p video: ~8-12 fps
- 4K video: ~3-5 fps

## Troubleshooting

**"No face detected in target images"**
- Ensure target images contain clear, visible faces
- Try images with better lighting
- Face should occupy at least 20% of image

**"Cannot open video"**
- Check video file is not corrupted
- Ensure FFmpeg is installed
- Try converting video to MP4 format

**"Out of memory"**
- Reduce `batch_size` in config
- Process on CPU instead of GPU
- Use lower `output_quality`

**Wrong person selected as dominant**
- Check `output/analysis/dominant_face_report.txt`
- Adjust weights in config (increase `weight_frequency`)
- Ensure video has one clearly dominant person

## Technical Details

**Models Used:**
- **Face Detection**: InsightFace Buffalo_L
- **Face Recognition**: ArcFace (512-dim embeddings)
- **Face Swapping**: InsightFace inswapper_128.onnx
- **Face Enhancement**: GFPGAN v1.4 (optional)

**Similarity Threshold:**
- Face matching uses cosine similarity of ArcFace embeddings
- Default threshold: 0.4 (adjustable in code)

## License

This project uses several open-source components:
- InsightFace: MIT License
- GFPGAN: Apache 2.0 License

## Disclaimer

This tool is for research and educational purposes. Users are responsible for ensuring they have appropriate rights and permissions for any content they process.

## Credits

Built using:
- [InsightFace](https://github.com/deepinsight/insightface)
- [GFPGAN](https://github.com/TencentARC/GFPGAN)
- OpenCV, NumPy, and other open-source libraries
